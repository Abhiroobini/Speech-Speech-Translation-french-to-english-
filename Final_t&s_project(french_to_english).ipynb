{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOAHpeHZ/keLKLReNN7cdxT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhiroobini/Speech-Speech-Translation-french-to-english-/blob/main/Final_t%26s_project(french_to_english).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJ2i5fwv1U2y",
        "outputId": "039581b3-acb6-4c8c-c8b5-a33385165cb9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q openai-whisper\n",
        "!pip install -q openai-whisper transformers sentencepiece gtts torch\n"
      ],
      "metadata": {
        "id": "VN2whl9VbW_w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b48787c-79ad-4c3e-8d69-6d9666b36326"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/800.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.7/800.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit whisper transformers gtts\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUCky4uVAwNg",
        "outputId": "1374abe8-88a8-491e-b003-83c4fa946b16"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.45.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting whisper\n",
            "  Downloading whisper-1.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: gtts in /usr/local/lib/python3.11/dist-packages (2.5.4)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from whisper) (1.17.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.38.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Downloading streamlit-1.45.1-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: whisper\n",
            "  Building wheel for whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for whisper: filename=whisper-1.1.10-py3-none-any.whl size=41120 sha256=572ddf199d4e65a0a29f3a6b293a1184ac51e5d432807846b8ffb02c56ac0022\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/65/ee/4e6672aabfa486d3341a39a04f8f87c77e5156149299b5a7d0\n",
            "Successfully built whisper\n",
            "Installing collected packages: whisper, watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.45.1 watchdog-6.0.0 whisper-1.1.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import whisper\n",
        "import tempfile\n",
        "import streamlit as st\n",
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "from gtts import gTTS\n",
        "\n",
        "@st.cache_resource\n",
        "def load_whisper_model():\n",
        "    return whisper.load_model(\"base\")\n",
        "\n",
        "@st.cache_resource\n",
        "def load_translation_model(source_lang, target_lang):\n",
        "    model_name = f\"Helsinki-NLP/opus-mt-{source_lang}-{target_lang}\"\n",
        "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "    model = MarianMTModel.from_pretrained(model_name)\n",
        "    return tokenizer, model\n",
        "\n",
        "def transcribe_audio(audio_path):\n",
        "    model = load_whisper_model()\n",
        "    result = model.transcribe(audio_path)\n",
        "    return result[\"text\"], result[\"language\"]\n",
        "\n",
        "def translate_text(text, source_lang, target_lang):\n",
        "    tokenizer, model = load_translation_model(source_lang, target_lang)\n",
        "    tokens = tokenizer(text, return_tensors=\"pt\", padding=True)\n",
        "    translated = model.generate(**tokens)\n",
        "    return tokenizer.decode(translated[0], skip_special_tokens=True)\n",
        "\n",
        "def text_to_speech(text, lang_code):\n",
        "    tts = gTTS(text=text, lang=lang_code)\n",
        "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as fp:\n",
        "        tts.save(fp.name)\n",
        "        return fp.name\n",
        "\n",
        "st.set_page_config(page_title=\"Speech-to-Speech Translator\", layout=\"centered\")\n",
        "st.title(\"🎤 French to English Speech Translator\")\n",
        "\n",
        "uploaded_files = st.file_uploader(\"Upload a French audio file \", type=[\"mp3\"], accept_multiple_files=True)\n",
        "\n",
        "if uploaded_files:\n",
        "    if len(uploaded_files) > 20:\n",
        "        st.warning(\"Please upload a maximum of 20 files.\")\n",
        "    else:\n",
        "        file_names = [file.name for file in uploaded_files]\n",
        "        selected_filename = st.selectbox(\"Select one audio file to translate:\", file_names)\n",
        "\n",
        "        selected_file = next(file for file in uploaded_files if file.name == selected_filename)\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "        st.subheader(f\"📁 Selected File: `{selected_file.name}`\")\n",
        "\n",
        "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as tmp_audio:\n",
        "            tmp_audio.write(selected_file.read())\n",
        "            audio_path = tmp_audio.name\n",
        "\n",
        "        try:\n",
        "            with st.spinner(\"Transcribing audio...\"):\n",
        "                original_text, detected_lang = transcribe_audio(audio_path)\n",
        "                st.success(f\"Detected Language: `{detected_lang}`\")\n",
        "                st.text_area(\"📝 Transcribed Text\", original_text, height=150)\n",
        "\n",
        "            with st.spinner(\"Translating text...\"):\n",
        "                translated_text = translate_text(original_text, detected_lang, \"en\")\n",
        "                st.text_area(\"🌍 Translated Text\", translated_text, height=150)\n",
        "\n",
        "            with st.spinner(\"Generating audio...\"):\n",
        "                translated_audio_path = text_to_speech(translated_text, \"en\")\n",
        "                audio_file = open(translated_audio_path, 'rb')\n",
        "                audio_bytes = audio_file.read()\n",
        "                st.audio(audio_bytes, format='audio/mp3')\n",
        "                audio_file.close()\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"❌ Error processing `{selected_file.name}`: {e}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqHjJI-9AFGP",
        "outputId": "289d0810-31d8-46ce-b6be-910dd011b9e8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-05-15 12:22:50.694 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-15 12:22:50.700 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-15 12:22:51.135 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2025-05-15 12:22:51.140 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-15 12:22:51.141 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-15 12:22:51.142 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-15 12:22:51.143 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-15 12:22:51.144 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-15 12:22:51.145 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit whisper transformers gtts\n",
        "!npm install -g localtunnel\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d14AjBvSFpoI",
        "outputId": "9cd5a54a-ce55-499c-9b99-40dbe10c62e1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.45.1)\n",
            "Requirement already satisfied: whisper in /usr/local/lib/python3.11/dist-packages (1.1.10)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: gtts in /usr/local/lib/python3.11/dist-packages (2.5.4)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from whisper) (1.17.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.38.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K\n",
            "added 22 packages in 2s\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit openai-whisper transformers sentencepiece gtts pyngrok\n",
        "!apt-get install -y ffmpeg\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsaqAiHETPAM",
        "outputId": "e6df8f27-faf6-4ada-91e0-1b253577e55a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code = '''\n",
        "import os\n",
        "import whisper\n",
        "import tempfile\n",
        "import streamlit as st\n",
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "from gtts import gTTS\n",
        "\n",
        "# --- Load Models ---\n",
        "@st.cache_resource\n",
        "def load_whisper_model():\n",
        "    return whisper.load_model(\"base\")\n",
        "\n",
        "@st.cache_resource\n",
        "def load_translation_model(source_lang, target_lang):\n",
        "    model_name = f\"Helsinki-NLP/opus-mt-{source_lang}-{target_lang}\"\n",
        "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "    model = MarianMTModel.from_pretrained(model_name)\n",
        "    return tokenizer, model\n",
        "\n",
        "# --- Helper Functions ---\n",
        "def transcribe_audio(audio_path):\n",
        "    model = load_whisper_model()\n",
        "    result = model.transcribe(audio_path)\n",
        "    return result[\"text\"], result[\"language\"]\n",
        "\n",
        "def translate_text(text, source_lang, target_lang):\n",
        "    tokenizer, model = load_translation_model(source_lang, target_lang)\n",
        "    tokens = tokenizer(text, return_tensors=\"pt\", padding=True)\n",
        "    translated = model.generate(**tokens)\n",
        "    return tokenizer.decode(translated[0], skip_special_tokens=True)\n",
        "\n",
        "def text_to_speech(text, lang_code):\n",
        "    tts = gTTS(text=text, lang=lang_code)\n",
        "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as fp:\n",
        "        tts.save(fp.name)\n",
        "        return fp.name\n",
        "\n",
        "# --- Streamlit UI ---\n",
        "st.set_page_config(page_title=\"Speech-to-Speech Translator\", layout=\"centered\")\n",
        "st.title(\"🎤 French to English Speech Translator\")\n",
        "\n",
        "uploaded_files = st.file_uploader(\"Upload a French audio file \", type=[\"mp3\"], accept_multiple_files=True)\n",
        "\n",
        "# After uploading files\n",
        "if uploaded_files:\n",
        "    if len(uploaded_files) > 20:\n",
        "        st.warning(\"Please upload a maximum of 20 files.\")\n",
        "    else:\n",
        "        file_names = [file.name for file in uploaded_files]\n",
        "        selected_filename = st.selectbox(\"Select one audio file to translate:\", file_names)\n",
        "\n",
        "        selected_file = next(file for file in uploaded_files if file.name == selected_filename)\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "        st.subheader(f\"📁 Selected File: `{selected_file.name}`\")\n",
        "\n",
        "        # Save to temp\n",
        "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as tmp_audio:\n",
        "            tmp_audio.write(selected_file.read())\n",
        "            audio_path = tmp_audio.name\n",
        "\n",
        "        try:\n",
        "            with st.spinner(\"Transcribing audio...\"):\n",
        "                original_text, detected_lang = transcribe_audio(audio_path)\n",
        "                st.success(f\"Detected Language: `{detected_lang}`\")\n",
        "                st.text_area(\"📝 Transcribed Text\", original_text, height=150)\n",
        "\n",
        "            with st.spinner(\"Translating text...\"):\n",
        "                translated_text = translate_text(original_text, detected_lang, \"en\")\n",
        "                st.text_area(\"🌍 Translated Text\", translated_text, height=150)\n",
        "\n",
        "            with st.spinner(\"Generating audio...\"):\n",
        "                translated_audio_path = text_to_speech(translated_text, \"en\")\n",
        "                audio_file = open(translated_audio_path, 'rb')\n",
        "                audio_bytes = audio_file.read()\n",
        "                st.audio(audio_bytes, format='audio/mp3')\n",
        "                audio_file.close()\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"❌ Error processing `{selected_file.name}`: {e}\")\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "with open(\"app.py\", \"w\") as f:\n",
        "    f.write(code)\n",
        "\n",
        "print(\"✅ app.py saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afb3tfsq_3aI",
        "outputId": "58c809b6-0acc-4bb3-821e-e0c5fcc76f58"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ app.py saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "ngrok.set_auth_token(\"2x39wFGd5GCHA0GJhMOqbsUIO1R_52ScG3gTgokaisLTW2aaG\")\n"
      ],
      "metadata": {
        "id": "OsEdY2pGTl1j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3aac873-c1b2-4079-d962-74d301dd33fa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for tunnel in ngrok.get_tunnels():\n",
        "    ngrok.disconnect(tunnel.public_url)\n"
      ],
      "metadata": {
        "id": "oosYB70taMeJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "\n",
        "def run():\n",
        "    subprocess.run([\"streamlit\", \"run\", \"app.py\", \"--server.port\", \"8501\"])\n",
        "\n",
        "threading.Thread(target=run).start()\n",
        "\n",
        "time.sleep(5)\n",
        "\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"🌐 Public URL:\", public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_JxBcTxXfoz",
        "outputId": "f24dc8ba-4257-4d80-a4cc-efeb93b26209"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🌐 Public URL: NgrokTunnel: \"https://dd86-34-82-48-101.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jiwer\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYBxs9FV6A8l",
        "outputId": "bb1942a6-8505-4941-b11c-9550ae818da1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jiwer\n",
            "  Downloading jiwer-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.1.8)\n",
            "Collecting rapidfuzz>=3.9.7 (from jiwer)\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Downloading jiwer-3.1.0-py3-none-any.whl (22 kB)\n",
            "Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\n",
            "Successfully installed jiwer-3.1.0 rapidfuzz-3.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub\n",
        "!apt-get install ffmpeg\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5xh7kJ46Qsl",
        "outputId": "2f117093-9554-44f8-d833-8745a5c260a6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from gtts import gTTS\n",
        "import time  # Import time module\n",
        "\n",
        "# Setup: Define directory and phrases\n",
        "dataset_dir = \"french_audio_dataset\"\n",
        "os.makedirs(dataset_dir, exist_ok=True)\n",
        "\n",
        "phrases = [\n",
        "    (\"Bonjour tout le monde\", \"Hello everyone\"),\n",
        "    (\"Je m'appelle Marie\", \"My name is Marie\"),\n",
        "    (\"Comment ça va?\", \"How are you?\"),\n",
        "    (\"J'aime le chocolat\", \"I love chocolate\"),\n",
        "    (\"Il fait beau aujourd'hui\", \"The weather is nice today\"),\n",
        "    (\"Je suis fatigué\", \"I am tired\"),\n",
        "    (\"Où est la bibliothèque?\", \"Where is the library?\"),\n",
        "    (\"Je voudrais un café\", \"I would like a coffee\"),\n",
        "    (\"Parlez-vous anglais?\", \"Do you speak English?\"),\n",
        "    (\"Quelle heure est-il?\", \"What time is it?\"),\n",
        "    (\"J'habite à Paris\", \"I live in Paris\"),\n",
        "    (\"C'est une bonne idée\", \"That's a good idea\"),\n",
        "    (\"Merci beaucoup\", \"Thank you very much\"),\n",
        "    (\"Je ne comprends pas\", \"I do not understand\"),\n",
        "    (\"Pouvez-vous répéter?\", \"Can you repeat?\"),\n",
        "    (\"J'ai besoin d'aide\", \"I need help\"),\n",
        "    (\"Je suis étudiant\", \"I am a student\"),\n",
        "    (\"C'est délicieux\", \"It's delicious\"),\n",
        "    (\"Félicitations\", \"Congratulations\"),\n",
        "    (\"Bonne chance\", \"Good luck\")\n",
        "]\n",
        "\n",
        "# Function to generate and save audio using gTTS\n",
        "def generate_audio(text, filename):\n",
        "    try:\n",
        "        # Initialize gTTS for French text\n",
        "        tts = gTTS(text, lang='fr')\n",
        "        tts.save(filename)\n",
        "        print(f\"Saved: {filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating audio for {text}: {e}\")\n",
        "\n",
        "# Save audio files and metadata\n",
        "data = []\n",
        "for i, (fr_text, en_text) in enumerate(phrases, 1):\n",
        "    filename = f\"audio{i}.mp3\"\n",
        "    filepath = os.path.join(dataset_dir, filename)\n",
        "\n",
        "    # Generate the audio for French text\n",
        "    generate_audio(fr_text, filepath)\n",
        "\n",
        "    # Append metadata\n",
        "    data.append((filename, fr_text, en_text))\n",
        "\n",
        "# Add a small delay before saving files to ensure audio is saved properly\n",
        "time.sleep(2)\n",
        "\n",
        "# Save the metadata as a CSV file\n",
        "df = pd.DataFrame(data, columns=[\"Audio File\", \"French Text\", \"English Translation\"])\n",
        "csv_filepath = os.path.join(dataset_dir, \"references.csv\")\n",
        "df.to_csv(csv_filepath, index=False)\n",
        "\n",
        "print(\"\\n✅ Dataset generation complete. Check the audio files and references.csv.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "7ZpyIpb86m05",
        "outputId": "4ba327a3-28e2-45ad-aa9f-87b7ade33f97"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: french_audio_dataset/audio1.mp3\n",
            "Saved: french_audio_dataset/audio2.mp3\n",
            "Saved: french_audio_dataset/audio3.mp3\n",
            "Saved: french_audio_dataset/audio4.mp3\n",
            "Saved: french_audio_dataset/audio5.mp3\n",
            "Saved: french_audio_dataset/audio6.mp3\n",
            "Saved: french_audio_dataset/audio7.mp3\n",
            "Saved: french_audio_dataset/audio8.mp3\n",
            "Saved: french_audio_dataset/audio9.mp3\n",
            "Saved: french_audio_dataset/audio10.mp3\n",
            "Saved: french_audio_dataset/audio11.mp3\n",
            "Saved: french_audio_dataset/audio12.mp3\n",
            "Saved: french_audio_dataset/audio13.mp3\n",
            "Saved: french_audio_dataset/audio14.mp3\n",
            "Saved: french_audio_dataset/audio15.mp3\n",
            "Saved: french_audio_dataset/audio16.mp3\n",
            "Saved: french_audio_dataset/audio17.mp3\n",
            "Saved: french_audio_dataset/audio18.mp3\n",
            "Saved: french_audio_dataset/audio19.mp3\n",
            "Saved: french_audio_dataset/audio20.mp3\n",
            "\n",
            "✅ Dataset generation complete. Check the audio files and references.csv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import whisper\n",
        "from transformers import pipeline\n",
        "from jiwer import wer\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from nltk.tokenize import word_tokenize\n",
        "from gtts import gTTS\n",
        "import nltk\n",
        "import time\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Load the Whisper model (medium or large model for better accuracy)\n",
        "asr_model = whisper.load_model(\"medium\")  # Use \"medium\" or \"large\" for better accuracy\n",
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")\n",
        "\n",
        "# Load reference data\n",
        "df = pd.read_csv(\"/content/french_audio_dataset/references.csv\")\n",
        "\n",
        "# Prepare to store results\n",
        "results = []\n",
        "\n",
        "for i, row in df.iterrows():\n",
        "    file = row[\"Audio File\"]\n",
        "    ref_fr = row[\"French Text\"]\n",
        "    ref_en = row[\"English Translation\"]\n",
        "\n",
        "    print(f\"Processing: {file}\")\n",
        "    audio_path = os.path.join(\"french_audio_dataset\", file)\n",
        "\n",
        "    # Convert MP3 to WAV for better transcription quality (if needed)\n",
        "    if file.endswith(\".mp3\"):\n",
        "        sound = AudioSegment.from_mp3(audio_path)\n",
        "        wav_path = audio_path.replace(\".mp3\", \".wav\")\n",
        "        sound.export(wav_path, format=\"wav\")\n",
        "        audio_path = wav_path  # Update to the new .wav file\n",
        "\n",
        "    # Add a small delay before processing the audio file\n",
        "    time.sleep(0.5)\n",
        "\n",
        "    # Step 1: Transcribe\n",
        "    try:\n",
        "        hyp_fr = asr_model.transcribe(audio_path, language=\"fr\", task=\"transcribe\")[\"text\"]\n",
        "    except RuntimeError as e:\n",
        "        print(f\"Error transcribing {file}: {e}\")\n",
        "        hyp_fr = \"Transcription Error\"\n",
        "\n",
        "    # Only proceed if transcription was successful\n",
        "    if hyp_fr != \"Transcription Error\":\n",
        "        # Step 2: Translate\n",
        "        hyp_en = translator(hyp_fr, max_length=500)[0]['translation_text']\n",
        "\n",
        "        # Step 3: Synthesize (Optional, TTS)\n",
        "        try:\n",
        "            tts = gTTS(hyp_en, lang='en')\n",
        "            tts.save(f\"output_{i+1}.mp3\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error synthesizing audio for {file}: {e}\")\n",
        "\n",
        "        # Step 4: Evaluation - Compute WER and BLEU\n",
        "        wer_score = wer(ref_fr.lower(), hyp_fr.lower())\n",
        "        ref_tokens = [word_tokenize(ref_en.lower())]\n",
        "        hyp_tokens = word_tokenize(hyp_en.lower())\n",
        "        bleu = sentence_bleu(ref_tokens, hyp_tokens, smoothing_function=SmoothingFunction().method4)\n",
        "    else:\n",
        "        # If transcription failed, assign placeholder values for evaluation metrics\n",
        "        hyp_en = \"Translation Error\"\n",
        "        wer_score = float('inf')  # Indicate a very high error\n",
        "        bleu = 0.0  # Indicate no similarity\n",
        "\n",
        "    # Append the results to the list\n",
        "    results.append({\n",
        "        \"filename\": file,\n",
        "        \"ref_french\": ref_fr,\n",
        "        \"hyp_french\": hyp_fr,\n",
        "        \"ref_english\": ref_en,\n",
        "        \"hyp_english\": hyp_en,\n",
        "        \"WER\": round(wer_score, 3) if wer_score != float('inf') else 'N/A',\n",
        "        \"BLEU\": round(bleu, 3)\n",
        "    })\n",
        "\n",
        "# Save the results to a CSV file\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv(\"evaluation_results.csv\", index=False)\n",
        "\n",
        "# Print completion message\n",
        "print(\"\\n✅ Evaluation complete. Check 'evaluation_results.csv'\")\n"
      ],
      "metadata": {
        "id": "pqhp3C_I1SR7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad5602dc-419f-4dda-a104-36449756b861"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: audio1.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: audio2.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: audio3.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: audio4.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: audio5.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: audio6.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: audio7.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: audio8.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: audio9.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: audio10.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: audio11.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: audio12.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: audio13.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: audio14.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: audio15.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: audio16.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: audio17.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: audio18.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: audio19.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: audio20.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Evaluation complete. Check 'evaluation_results.csv'\n"
          ]
        }
      ]
    }
  ]
}